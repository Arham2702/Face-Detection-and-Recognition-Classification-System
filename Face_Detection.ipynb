{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5-lfJqgqR8fL",
    "outputId": "be8a4202-5327-4376-978e-5f3efcdb5afb"
   },
   "outputs": [],
   "source": [
    "#!pip install roboflow\n",
    "\n",
    "#from roboflow import Roboflow\n",
    "#rf = Roboflow(api_key=\"7uLbvv49VaQCbnnNV7AL\")\n",
    "#project = rf.workspace(\"university-f6psq\").project(\"family-face-detection-2c9cd\")\n",
    "#dataset = project.version(1).download(\"yolov5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SciPy in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SciPy) (1.23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.2.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.23.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\event2\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ppgIuTIPTcn1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "WC_nk4xLU_tN",
    "outputId": "d038f77d-c3d8-4438-ff0b-cb314902adaf"
   },
   "outputs": [],
   "source": [
    "image = image.load_img('Data//Train//Arham//1.jpg')\n",
    "#plt.imshow(image) #ðŸ’€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "FnoYGkySakuF",
    "outputId": "a00277f7-9b5a-46ed-e3df-f4becea231ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image = cv2.imread('Data\\\\Train\\\\Arham\\\\1.jpg')\n",
    "cv2.imshow('graycsale image',Image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OEhv23peAQ2",
    "outputId": "eb0c44fe-0dfa-4c9e-a4a1-e311c73423e8"
   },
   "outputs": [],
   "source": [
    "cv2.imread('/content/Family-Face-Detection-1/train/images/IMG_20230318_224805_jpg.rf.5b081b96854a0d114d9154217bb46c7e.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bHsSUfAeE7F",
    "outputId": "5ffdfcc2-a1a5-4750-daeb-f08aee0cca5a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "Image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i_bgrciJeMhu"
   },
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale = 1/255)\n",
    "validation = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TqWHkH3bRLcZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = train.flow_from_directory('DLprojectdataset//Train//',\n",
    "                                          target_size = (200,200),\n",
    "                                          batch_size = 3,\n",
    "                                          class_mode = 'categorical')\n",
    "\n",
    "validation_dataset = validation.flow_from_directory('DLprojectdataset//Validation//',\n",
    "                                          target_size = (200,200),\n",
    "                                          batch_size = 3,\n",
    "                                          class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eeshawar': 0, 'Jaiman': 1, 'Yash': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (200,200,3)),\n",
    "                                   tf.keras.layers.MaxPool2D(2,2),\n",
    "                                    \n",
    "                                   tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "                                   tf.keras.layers.MaxPool2D(2,2),\n",
    "                                   \n",
    "                                   tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "                                   tf.keras.layers.MaxPool2D(2,2),\n",
    "                                   \n",
    "                                   tf.keras.layers.Flatten(),\n",
    "                                   \n",
    "                                   tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "                                   \n",
    "                                   tf.keras.layers.Dense(3, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = RMSprop(learning_rate = 0.001),\n",
    "             metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 5s 519ms/step - loss: 13.1391 - accuracy: 0.4000 - val_loss: 1.0494 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 2s 417ms/step - loss: 1.2113 - accuracy: 0.2667 - val_loss: 1.1430 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 2s 414ms/step - loss: 1.1075 - accuracy: 0.4000 - val_loss: 1.0460 - val_accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 2s 402ms/step - loss: 1.0939 - accuracy: 0.4667 - val_loss: 1.1112 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 1.0772 - accuracy: 0.4000 - val_loss: 1.0721 - val_accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 2s 408ms/step - loss: 1.1146 - accuracy: 0.3333 - val_loss: 1.2134 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 2s 410ms/step - loss: 1.3973 - accuracy: 0.2667 - val_loss: 1.0321 - val_accuracy: 0.5333\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 1.1953 - accuracy: 0.6667 - val_loss: 1.0974 - val_accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 2s 409ms/step - loss: 1.0124 - accuracy: 0.5333 - val_loss: 1.0998 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 2s 418ms/step - loss: 1.1177 - accuracy: 0.4667 - val_loss: 0.9895 - val_accuracy: 0.4667\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 2s 414ms/step - loss: 1.0338 - accuracy: 0.4000 - val_loss: 0.9484 - val_accuracy: 0.8667\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 2s 411ms/step - loss: 0.9487 - accuracy: 0.4667 - val_loss: 0.8464 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 2s 410ms/step - loss: 0.9874 - accuracy: 0.7333 - val_loss: 0.9236 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 2s 404ms/step - loss: 1.7080 - accuracy: 0.6667 - val_loss: 0.7588 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 2s 414ms/step - loss: 1.3060 - accuracy: 0.7333 - val_loss: 0.7230 - val_accuracy: 0.8667\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 2s 408ms/step - loss: 0.7001 - accuracy: 0.6667 - val_loss: 0.6205 - val_accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 2s 408ms/step - loss: 0.9441 - accuracy: 0.6000 - val_loss: 0.5754 - val_accuracy: 0.8000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 2s 414ms/step - loss: 0.8557 - accuracy: 0.7333 - val_loss: 0.6224 - val_accuracy: 0.9333\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 2s 412ms/step - loss: 0.5489 - accuracy: 0.8000 - val_loss: 0.4587 - val_accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 2s 402ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 2s 416ms/step - loss: 0.6558 - accuracy: 0.7333 - val_loss: 0.4947 - val_accuracy: 0.8667\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 2s 404ms/step - loss: 0.4127 - accuracy: 0.8667 - val_loss: 0.3359 - val_accuracy: 0.9333\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.2393 - accuracy: 0.9333 - val_loss: 1.1262 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 2s 515ms/step - loss: 1.0367 - accuracy: 0.7333 - val_loss: 0.3944 - val_accuracy: 0.8667\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 2s 413ms/step - loss: 0.4132 - accuracy: 0.9333 - val_loss: 0.4853 - val_accuracy: 0.9333\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 2s 412ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 2s 407ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.8667\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 2s 407ms/step - loss: 0.8472 - accuracy: 0.5333 - val_loss: 0.4595 - val_accuracy: 0.7333\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 2s 409ms/step - loss: 0.1842 - accuracy: 0.8667 - val_loss: 0.4534 - val_accuracy: 0.9333\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 2s 417ms/step - loss: 0.4619 - accuracy: 0.8000 - val_loss: 0.4262 - val_accuracy: 0.8000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 0.1974 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.8000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 2s 407ms/step - loss: 0.5860 - accuracy: 0.8000 - val_loss: 0.3788 - val_accuracy: 0.8667\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 2s 410ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8667\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 2s 407ms/step - loss: 0.0991 - accuracy: 0.9333 - val_loss: 1.9983 - val_accuracy: 0.4667\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 2s 441ms/step - loss: 1.2352 - accuracy: 0.8000 - val_loss: 1.2692 - val_accuracy: 0.6000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 2s 420ms/step - loss: 0.7015 - accuracy: 0.7333 - val_loss: 0.3393 - val_accuracy: 0.8667\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 2s 415ms/step - loss: 0.1324 - accuracy: 0.9333 - val_loss: 0.3149 - val_accuracy: 0.8667\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 2s 403ms/step - loss: 0.4035 - accuracy: 0.9333 - val_loss: 0.4457 - val_accuracy: 0.8667\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 2s 411ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9333\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 0.4593 - accuracy: 0.9333 - val_loss: 0.1362 - val_accuracy: 0.9333\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 0.1745 - accuracy: 0.9333 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 2s 408ms/step - loss: 0.1280 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 2s 454ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 2s 473ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 2s 413ms/step - loss: 0.1129 - accuracy: 0.9333 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 2s 408ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 0.1929 - accuracy: 0.8667 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 2s 411ms/step - loss: 2.2258 - accuracy: 0.7333 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 2s 409ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 2s 407ms/step - loss: 0.0803 - accuracy: 0.9333 - val_loss: 0.0331 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_dataset,\n",
    "                     steps_per_epoch = 5,\n",
    "                     epochs = 50,\n",
    "                     validation_data = validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eeshawar': 0, 'Jaiman': 1, 'Yash': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "[[0. 0. 1.]]\n",
      "0\n",
      "Yash\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[0. 0. 1.]]\n",
      "1\n",
      "Yash\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[0. 0. 1.]]\n",
      "2\n",
      "Yash\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[[0. 0. 1.]]\n",
      "3\n",
      "Yash\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0. 1. 0.]]\n",
      "4\n",
      "Jaiman\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0. 0.]]\n",
      "5\n",
      "Eeshawar\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.2395799e-20]]\n",
      "6\n",
      "Eeshawar\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0. 0. 1.]]\n",
      "7\n",
      "Yash\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[[1. 0. 0.]]\n",
      "8\n",
      "Eeshawar\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[[1. 0. 0.]]\n",
      "9\n",
      "Eeshawar\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0. 1. 0.]]\n",
      "10\n",
      "Jaiman\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0. 1. 0.]]\n",
      "11\n",
      "Jaiman\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0. 1. 0.]]\n",
      "12\n",
      "Jaiman\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[0. 1. 0.]]\n",
      "13\n",
      "Jaiman\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 3.3536889e-21]]\n",
      "14\n",
      "Jaiman\n"
     ]
    }
   ],
   "source": [
    "dir_path = 'DLprojectdataset//Test//'\n",
    "y_pred = []\n",
    "count = 0\n",
    "for i in os.listdir(dir_path):\n",
    "    img = image.load_img(dir_path + '//' + i, target_size = (200,200))\n",
    "    #plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X, axis = 0)\n",
    "    images = np.vstack([X])\n",
    "    \n",
    "    val = model.predict(images)\n",
    "    print(val)\n",
    "    print(count)\n",
    "    count += 1\n",
    "    val = val.squeeze()\n",
    "    if val[0] == 1:\n",
    "        y_pred.append(\"Eeshawar\")\n",
    "        print(\"Eeshawar\")\n",
    "    elif val[1] == 1:\n",
    "        y_pred.append(\"Jaiman\")\n",
    "        print(\"Jaiman\")\n",
    "    elif val[2] == 1:\n",
    "        y_pred.append(\"Yash\")\n",
    "        print(\"Yash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "y_true = [\"Yash\", \"Yash\", \"Yash\", \"Yash\", \"Yash\", \"Eeshawar\", \"Eeshawar\", \"Eeshawar\", \"Eeshawar\", \"Eeshawar\", \"Jaiman\", \"Jaiman\", \"Jaiman\", \"Jaiman\", \"Jaiman\" ]\n",
    "#y_pred = [\"Arham\", \"Arham\", \"Asif\", \"Arham\", \"Arham\", \"Arham\", \"Asif\", \"Asif\", \"Asif\", \"Asif\", \"Asif\", \"Asif\", \"Fateen\", \"Arham\", \"Fateen\", \"Fateen\", \"Arham\", \"Fateen\", ]\n",
    "conf = confusion_matrix(y_true, y_pred)\n",
    "print(len(y_true), len(y_pred))\n",
    "score = 0\n",
    "for i in range(len(y_true)):\n",
    "    if y_pred[i] == y_pred[i]:\n",
    "        score += 1\n",
    "print(f\"Accuracy: {(score/len(y_true))*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Eeshawar       1.00      1.00      1.00         5\n",
      "      Jaiman       0.62      1.00      0.77         5\n",
      "        Yash       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.88      0.80      0.78        15\n",
      "weighted avg       0.88      0.80      0.78        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fateen\n"
     ]
    }
   ],
   "source": [
    "if val[0][0] == 1:\n",
    "    print(\"Arham\")\n",
    "elif val[0][1] == 1:\n",
    "    print('Asif')\n",
    "elif val[0][2] == 1:\n",
    "    print(\"Fateen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "cascade_path = pathlib.Path(cv2.__file__).parent.absolute() / \"data/haarcascade_frontalface_default.xml\"\n",
    "print(cascade_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv2.CascadeClassifier(str(cascade_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mEvent2\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mJupyter\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "classifier =load_model(r'C:\\Users\\Event2\\Desktop\\Jupyter\\checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m camera \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, 200, 200, 3), found shape=(None, 200, 1, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [117]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m roi \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(roi)\n\u001b[0;32m     22\u001b[0m roi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(roi, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m label \u001b[38;5;241m=\u001b[39m faces_labels[prediction\u001b[38;5;241m.\u001b[39margmax()]\n\u001b[0;32m     26\u001b[0m label_position \u001b[38;5;241m=\u001b[39m (x,y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetsy62kkg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Event2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, 200, 200, 3), found shape=(None, 200, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    _, frame = camera.read()\n",
    "    labels=[]\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(\n",
    "    gray_image,\n",
    "    scaleFactor = 1.1,\n",
    "    minNeighbors = 5,\n",
    "    minSize = (30,30),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    \n",
    "    for(x, y, width, height) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+width, y+height), (255, 255, 0), 2)\n",
    "        #cv2.putText(frame, 'Arham', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "        roi_gray = gray_image[y:y+height, x:x+width]\n",
    "        #roi_gray = cv2.resize(roi_gray,(200,200), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        if np.sum([roi_gray]) != 0.0:\n",
    "            roi = roi_gray.astype(\"float\") / 255.0\n",
    "            roi = image.img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=-1)\n",
    "            \n",
    "            prediction = model.predict(roi)\n",
    "            label = faces_labels[prediction.argmax()]\n",
    "            label_position = (x,y)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "    cv2.imshow(\"Faces\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x23088104970>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "    val = train_dataset.class_indices[model.predict(images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    " if np.sum([faces]) != 0.0:\n",
    "        roi = faces.astype(\"float\") / 255.0\n",
    "        roi = image.img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
